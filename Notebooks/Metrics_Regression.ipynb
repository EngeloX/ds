{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e6c6d1-0bf6-4ab7-990c-a13fe4eb4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=3_000, n_features=5, n_informative=3, noise=33, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d44668-8e67-41f4-bc58-1da90ad53aed",
   "metadata": {},
   "source": [
    "# Mean Absolute Error\n",
    "Средняя разница между фактическими значениями и предсказанными по модулю.\\\n",
    "Метрика устойчива к выбросам, однако не учитывает масштаб и направление ошибок\n",
    "$$MAE = \\frac{1}{N}\\sum_{i=1}^N{|y_i-\\hat{y_i}|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43544f71-1373-45bf-aa1f-7e01e07bec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1318593-956f-45f2-9882-b5742ecdf83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.050203889364692"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70062e-6552-45c7-8aae-ce2a743a1407",
   "metadata": {},
   "source": [
    "## Mean Absolute Percentage Error\n",
    "Позволяет оценить насколько в среднем прогнозы модели отличаются относительно реальных значений в процентном отношении.\\\n",
    "При $y$=0 выдает неадекватное значения из за нуля в знаминателе. Искажается при маленьких значениях $y$.\n",
    "$$MAPE=\\frac{1}{N}\\sum_{i=1}^N{\\frac{|y_i-\\hat{y_i}|}{y_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cd8c51-6152-4bdb-9f44-d137b57f7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b166cc-0943-4513-803c-d8b96635a081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1721101322769907"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6a7c7-2a19-41d0-a709-926147b71040",
   "metadata": {},
   "source": [
    "## Symmetric Mean Absolute Percentage Error\n",
    "Модификация над **MAPE** выражает ошибку прогноза в процентах, но более сбалансированно.\\\n",
    "Устраняет асимметрию при отклонениях от малых значений и проблему деления на ноль\\\n",
    "*(Но сумма двух модулей в знаминателе в некоторых случаях все равно может составить ноль)*\n",
    "\n",
    "Не учитывает относительную значимость наблюдений и плохо работает с неравномерными данными.\n",
    "\n",
    "$$SMAPE=\\frac{1}{N}\\sum_{i=1}^N{\\frac{2|y_i-\\hat{y_i}|}{|y_i|+|\\hat{y_i}|}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9255ee72-c54d-4a20-9c57-224a90e44c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    numerator = 2*np.abs(y_true - y_pred)\n",
    "    denominator = np.abs(y_true)+np.abs(y_pred)\n",
    "    smape = np.mean(numerator[denominator != 0] / denominator[denominator!=0])\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e08d252-7c67-4b69-b4de-90a6a4c8525d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7382988418430133"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetric_mean_absolute_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03efbff-58e4-4be8-8d0f-f786228bf420",
   "metadata": {},
   "source": [
    "## Weighted Average Percentage Error\n",
    "Нормализует общую ошибку к общей сумме фактических значений \\\n",
    "Использует взвешенное среднее абсолютных ошибок, где вес — это размер фактических значений. \\\n",
    "Эффективна, когда данные с сильно разными масштабами.\n",
    "$$WAPE=\\frac{\\sum_{i=1}^N{|y_i-\\hat{y_i}|}}{\\sum_{i=1}^N{|y_i|}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5055553-c9da-4dd7-ad49-68b70446c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    numerator = np.sum(np.abs(y_true - y_pred))\n",
    "    denominator = np.sum(np.abs(y_true))\n",
    "    wape = numerator/denominator\n",
    "    return wape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a02bf7b-0c29-46df-a079-8d10859f1f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40434787506534264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_average_percentage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549d533a-73ee-4a43-820e-4fa3acb30fb0",
   "metadata": {},
   "source": [
    "# Mean Squared Error\n",
    "Средняя разница между фактическими значениями и предсказанными в квадрате.\\\n",
    "Метрика делает акцент на больших ошибках, чувствительна к выбросам.\n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^N{(y_i-\\hat{y_i})^2}$$\n",
    "Извлечение квадратного корня возвращает значение к исходной размерности и улучшает интепритируемость.\n",
    "$$RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N{(y_i-\\hat{y_i})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67baf33c-21a9-4b6c-9463-09a30506d920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1121.915175038442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "33.49500223971394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "display(\n",
    "    mean_squared_error(y_test, y_pred),\n",
    "    root_mean_squared_error(y_test, y_pred)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d972e-19c7-4a44-be3e-23b50c1ec99b",
   "metadata": {},
   "source": [
    "## Mean Squared Logarithmic Error\n",
    "Альтернативный способ перехода от абсолютных ошибок к относительным - измерение в логорифмическом масштабе.\\\n",
    "Метрика может быть применима лишь для неотрицательных меток\n",
    "\n",
    "Константа $c$ - вводится искуственно для избегания логорифма от нуля.\\\n",
    "Устойчива к выбросам, поскольку делает распределение целевых и спрогнозированных значений более однородным. \\\n",
    "Труднее интерпретировать, уделяет больше внимания заниженным прогнозам, поскольку логарифм является несимметричной функцией.\n",
    "$$MSLE = \\frac{1}{N}\\sum_{i=1}^N{(ln(y_i+c)-ln(\\hat{y_i}+c))^2}$$\n",
    "$$RMSLE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N{(ln(y_i+c)-ln(\\hat{y_i}+c))^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5405ca9-be0c-4a6d-8d69-636563381114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error, root_mean_squared_log_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcae3f9-7fa3-4bec-9e02-edfa19d5a90c",
   "metadata": {},
   "source": [
    "# $R^2$ score\n",
    "Коэффициент детерминации - показывает какая доля дисперсии(разброса) объясняется моделью\\\n",
    "Не учитывает количество признаков в модели. Имеет тенденцию к увеличению при добавлении новых признаков в обучающий набор, даже если они не улучшают качество модели. Сравнение моделей с разным количеством признаков становится некорректным\n",
    "$$R^2=1-\\frac{RSS}{TSS}$$\n",
    "$$TSS = \\sum_{i=1}^n (y-\\bar{y})^2 \\hspace{5cm} RSS = \\sum_{i=1}^n (y-\\hat{y})^2$$\n",
    "\n",
    "$TSS$ - **Total Sum of Squares** Общая сумма квадратов отклонений от среднего.\\\n",
    "$RSS$ - **Residual Sum of Squares** Сумма квадратов остатков\\\n",
    "$\\bar{y}$ - Общее реднее значение выборки\\\n",
    "$\\hat{y}$ - Предсказанное значение\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "393c0ad4-d82d-489b-a977-bf129f3b602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456162138953873"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9f4bc-3452-4294-9131-52d061f2dabf",
   "metadata": {},
   "source": [
    "## Adjusted $R^2$ score\n",
    "Скорректированный коэффициент детерминации. Вводит штраф за добавление новых признаков.\n",
    "$$R^2_{adj}=1-\\frac{RSS(n-1)}{TSS(n-k-1)}=1-\\frac{(1-R^2)(n-1)}{n-k-1}$$\n",
    "$k$ - Количество признаков.\\\n",
    "$n$ - Количество образцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17ab02fc-8d23-4703-a6f4-d26823ccfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2_score(y_true, y_pred, X_shape):\n",
    "    n, k = X_shape\n",
    "    RSS = np.sum((y_true - y_pred)**2)\n",
    "    TSS = np.sum((y_true - np.mean(y_true))**2)\n",
    "    r2 = 1 - RSS/TSS\n",
    "    return 1 - ((1-r2)*(n-1)) / (n-k-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a75dd736-fd34-498b-903e-082653680820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443166870763249"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_r2_score(y_test, y_pred, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c26b9-84a5-463d-8a3b-031355d7427e",
   "metadata": {},
   "source": [
    "# Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fadc0a-235d-48f4-9fa3-bb1e3d073836",
   "metadata": {},
   "source": [
    "**Bias** - Смещение. Недообученность модели. Прогнозы стабильно в среднем отклоняются от истины. \\\n",
    "**Variance** - Разброс. Переобученность модели. Прогнозы разбросаны вокруг истины. Модель подражает конкретной выборке, не обобщается.\n",
    "\n",
    "**Biance-Variance trade-off** - Поиск наиболее сбалансированной модели между смещением и разбросом.\\\n",
    "Увеличение сложности модели -> уменьшается смещение, растет разброс\\\n",
    "Упрощение модели -> увеличивает смещение, уменьшает разброс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd70f11-c075-4ded-9250-08233958e778",
   "metadata": {},
   "source": [
    "**MSE** для образца $x$ — это среднее значение квадрата разности между истинным $y=f(x)+\\epsilon$ и предсказанием модели $\\hat{f}(x)$ если усреднить по всем возможным обучающим выборкам и всем возможным шумам в данных.\n",
    "$$\n",
    "MSE(x) = \\mathbb{E}_{D, \\epsilon} [(y-\\hat{f}(x))^2]\n",
    "$$\n",
    "$x$ - Образец данных\\\n",
    "$y=f(x)+\\epsilon$ - Истинный закон + случайный шум\\\n",
    "$\\hat{f}(x))$ - Прогноз модели, обученной на случайной выборке из $D$\\\n",
    "$\\mathbb{E}_{D, \\epsilon}$ - Математическое ожидание по выборке и шуму\\\n",
    "$\\epsilon$ - Случайный шум с $\\mathbb{E}[\\epsilon]=0$ и  $Var(\\epsilon) =\\mathbb{E}[\\epsilon^2] = \\sigma^2$\n",
    "\n",
    "$$MSE(x) = \\mathbb{E}_{D, \\epsilon} [(f(x)+\\epsilon-\\hat{f}(x))^2] = $$\n",
    "$$=\\mathbb{E}_{D, \\epsilon} \\Big[\\Big(\\big(f(x)-\\hat{f}(x)\\big)+\\epsilon\\Big)^2\\Big] = $$\n",
    "$$= \\mathbb{E}_{D, \\epsilon}\\Big[  \\big(f(x)-\\hat{f}(x)\\big)^2     +2\\big(f(x)-\\hat{f}(x)\\big)\\epsilon        + \\epsilon^2  \\Big] =$$\n",
    "\n",
    "$$ =\\mathbb{E}_{D, \\epsilon}\\Big[  \\big(f(x)-\\hat{f}(x)\\big)^2\\Big] + \\mathbb{E}_{D, \\epsilon}\\Big[ 2\\big(f(x)-\\hat{f}(x)\\big)\\epsilon \\Big]         + \\mathbb{E}_{D, \\epsilon}\\Big[ \\epsilon^2\\Big] =  $$\n",
    "\n",
    "**Третий член**\\\n",
    "$\\mathbb{E_\\epsilon}[\\epsilon^2] = \\sigma^2$\n",
    "\n",
    "\n",
    "**Второй член**\\\n",
    "$\\epsilon$ и $\\hat{f}(x)$ независимы(шум появляется после обучения модели), $\\mathbb{E}[\\epsilon]=0$\\\n",
    "$\\mathbb{E}_{D, \\epsilon}\\Big[ 2\\big(f(x)-\\hat{f}(x)\\big)\\epsilon \\Big]         =   \\mathbb{E}_{D}\\Big[ (f(x)-\\hat{f}(x)) * \\underbrace{\\mathbb{E}[\\epsilon}_0] \\Big]    =0$\n",
    "\n",
    "**Разложение дисперсии**\n",
    "\n",
    "Для случайной величины $Z$ и ее математического ожидания $\\mathbb{E}[Z]$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[(Z - \\mu)^2] = Var(Z) + Bias(Z)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "Var(Z) = \\mathbb{E}[(Z - \\mathbb{E}[Z])^2] \n",
    "$$\n",
    "$$\n",
    "Bias(Z)^2 = (\\mathbb{E}[Z]-\\mu)^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$Z$ - Некая случайная величина\\\n",
    "$\\mu$ - Истинное значение, с которым сравнивается $Z$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "$$MSE(x) = \\mathbb{E}_D  \\Big[    \\Big(f(x)-\\hat{f}(x)\\Big)^2  \\Big] + \\sigma^2$$\n",
    "\n",
    "$$\n",
    "MSE(x) = \\underbrace{\\mathbb{E}_D [(\\hat{f}(x) - \\mathbb{E}_D[\\hat{f}(x)])^2]}_{variance}     +    \\underbrace{(\\mathbb{E}[\\hat{f}(x)]- f(x))^2}_{bias^2} + \\underbrace{\\sigma^2}_{noise}\n",
    "$$\n",
    "$$\n",
    "MSE(x) = Var[\\hat{f}(x)] + Bias[\\hat{f}(x)]^2 + \\sigma^2\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
