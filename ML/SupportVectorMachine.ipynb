{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9cd6bd-bbcc-4f4b-8f23-bb1e4b5b4d8d",
   "metadata": {},
   "source": [
    "460 - Прикладное\n",
    "220 - Для сложных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2958848-a68c-4ab2-a6ca-9c061dc0a9e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "`Support Vector Machine`: Способ выбрать функцию, что будет наилучшим(оптимальным) образом разделять точки на классы гиперплоскостью.\\\n",
    "Лучшая - та что **минимизирует функцию потерь**, то есть значения ошибки будет минимально возможным в данной ситуации. И **максимизирует зазор(margin)**\n",
    "$$\n",
    "f(x) = w^TX+b\n",
    "$$\n",
    "$$\n",
    "f(x) = w^TX\n",
    "$$\n",
    "$w$ - вектор весов, который определяет направление и наклон гиперплоскости\n",
    "\n",
    "**Решающее правило**: \n",
    "$$\n",
    "sign(w^TX+b)\n",
    "$$\n",
    "`Бинарная классификация`: Знак определяет на какой стороне гиперплоскости лежит точка, следовательно к какому из классов принадлежит. (-1, +1)\n",
    "\n",
    "----\n",
    "\n",
    "**Функция потерь  `hinge-loss`:** \n",
    "$$\n",
    "hinge = max(0, 1-y_if(x)) = max(0, 1 - y_i(w^Tx+b))\n",
    "$$\n",
    "$y_i$ - Настоящий класс \\\n",
    "$w^T+b$ - Число. Насколько далеко далеко от гиперплоскости и с какой стороны она находится. Значение \"Насколько\" уверенно была сделана классификация.\n",
    "Минимизировать ошибку и максимизировать зазор \\\n",
    "Далее выбирается наибольшее($max$) число между $0$ и $1-y_i(w^T+b)$:\n",
    "\n",
    "Если модель не ошиблась то произведение $yf(x)$ будет положительным(**минус на минус** и **плюс на плюс**) а разность **1 - $yf(x)$** будет отрицательная.\\\n",
    "=> Наибольшим числом будет выбираться 0(Ошибки нет)\\\n",
    "При ошибки модели разность знаков даст отрицательное произведение $yf(x)$ а единица минус отрицательное значение дадут положительное\\\n",
    "=> Наибольшим числом будет это значение разности с единицей(то есть уже сумма) а не ноль(ошибка)\n",
    "\n",
    "----\n",
    "**`margin`(Зазор)**: Ширина \"коридора\" между двумя ближайшими точками противоположных классов от разделяющей гиперплоскости.\\\n",
    "Разделяющая линия или плоскость идет ровно по центру между классами. =>\n",
    "Зазор — это расстояние от самой этой линии до ближайшей точки сверху плюс расстояние до ближайшей точки снизу.\\\n",
    "**Отступ одной точки от разделяющей линии** это половина зазора.\n",
    "\n",
    "Геометрический отступ **Margin** = $\\frac{1}{||w||}$\\\n",
    "Полный зазор = $\\frac{2}{||w||}$\n",
    "\n",
    "$$\n",
    "maximize \\frac{|w^Tx+b|}{||w||} = minimize \\frac{1}{2}||w||^2\n",
    "$$\n",
    "$||w||$ - длина весов $w$ = $\\sqrt{{w_1}^2+{w_2}^2+...+{w_n}^2}$\\\n",
    "В знаменателе, следовательно её уменьшение увеличивает зазор.\n",
    "\n",
    "\n",
    "-----\n",
    "**`Целевая функция в мягкой форме (Soft Margin SVM)`**:\\\n",
    "Найти такие веса ($w$ и $b$) которые:\n",
    "- Максимизируют зазор-**margin**(Разделение классов)\n",
    "- Минимизируют ошибку классификации(**hinge loss**)\n",
    "\n",
    "$$\n",
    "min\\frac{1}{2}||w||^2 +C \\sum{max(0, 1 - y_i(w^Tx+b))}\n",
    "$$\n",
    "$C$ - Гиперпараметр штрафа. Насколько сильно модель штрафует себя за ошибки.\n",
    "- Большое $C$ - Модель **жестко** штрафует ошибки.(Может переобучиться)\n",
    "- Маленькое $C$ - Модель **слабее** штрафует ошибки. (Может ошибаться но имеет лучшее обобщение)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e0749-a718-453e-bdd6-3df704f53816",
   "metadata": {},
   "source": [
    "**Классификация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "88762a09-cff1-49b0-8a2b-3b1f93c009cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a27c34-a1fa-42e1-9b0b-3d74a47c46cc",
   "metadata": {},
   "source": [
    "**Регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "93447fe1-f0b4-46f4-ba94-c4e948669e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef7be7-3a50-498b-bae4-fdefa1921c18",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6aef3d-b0af-4183-b82e-8fdaa9205a74",
   "metadata": {},
   "source": [
    "# Квадратичное программирование (QP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031616e-e350-4a07-a9d9-a6fc2099266f",
   "metadata": {},
   "source": [
    "# Sequential Minimal Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681232d-4ca1-4d5c-99df-908157430763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
